# Configuration the Penn-to-Dependency corpus, automatically converted from
# constituent trees to dependencies as per Richard Johansson and Pierre Nugues,
# Extended Constituent-to-dependency Conversion for English, Proceedings of
# NODALIDA 2007, May 25-26, 2007, Tartu, Estonia,
# http://nlp.cs.lth.se/software/treebank_converter/">http://nlp.cs.lth.se/software/treebank_converter/
#
# Configuration author: Assaf Urieli

languagePack="languagePacks/english/languagePack/"

input-pattern="%INDEX%\t%TOKEN%\t.*?\t%POSTAG%\t.*?\t.*?\t%GOVERNOR%\t%LABEL%\t.*?\t.*?"

corpus-rules = [
  {
    criteria = { TOKEN = "(``|'')" }
    actions = {
      TOKEN = "\""
    }
  },
  {
    criteria = { POSTAG = "(``|'')" }
    actions = {
      POSTAG = "P"
      TOKEN = "\""
    }
  },
  {
    criteria = { POSTAG = "[,:.()]" }
    actions = { POSTAG = "P" }
  },
  {
    criteria = { POSTAG = "#" }
    actions = {
      POSTAG = "NNS"
      TOKEN = "£"
    }
  },
  {
    criteria = { POSTAG = "[$£¥]" }
    actions = { POSTAG = "NNS" }
  },
  {
    criteria = { POSTAG = "%" }
    actions = { POSTAG = "NN" }
  }
]

talismane {
  core {
    en = ${talismane.core.generic} {
      locale = en
    
      lexicons = [
        ${languagePack}"lexicons_en.zip"
      ]
      
      annotators {
        text-annotators = [
          ${languagePack}"text_marker_filters.txt"
        ]
        
        sentence-annotators = [
          ${languagePack}"token_filters.txt"
        ]
      }
      
      sentence-detector {
        train {
          corpus-reader = com.joliciel.talismane.tokeniser.TokenRegexBasedCorpusReader
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features = "languagePacks/english/features/sentenceDetector_en_baseline.txt"
        }
      }
      
      tokeniser {
        type = pattern

        filters = [
          com.joliciel.talismane.tokeniser.filters.QuoteNormaliser
          com.joliciel.talismane.tokeniser.filters.LowercaseKnownFirstWordFilter
          com.joliciel.talismane.tokeniser.filters.UppercaseSeriesFilter
        ]
        
        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="languagePacks/english/features/tokeniser_en_baseline.txt"
          patterns="languagePacks/english/features/tokeniserPatterns_en.txt"
        }
      }
      
      pos-tagger {
        pos-tag-set = ${languagePack}"pennTagset.txt"
        
        pos-tag-map = {
          Dela = ${languagePack}"dela-en_posTagMap.txt"
        }
        
        rules = [
          ${languagePack}"posTaggerConstraints_en.txt"
        ]

        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="languagePacks/english/features/posTagger_en_baseline.txt"
        }
      }
      
      parser {      
        dependency-labels = ${languagePack}"pennDependencyLabels.txt"
        
        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="languagePacks/english/features/parser_en_baseline.txt" 
        }
        
      }
    }
  }
}
